name: HF Auto-Merge Additive PRs

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"  # self-adapt level=4
concurrency:
  group: hf-auto-merge-additive-prs-cron
  cancel-in-progress: false

jobs:
  auto_merge:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          persist-credentials: false

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install "huggingface_hub>=0.24.0"

      - name: Auto-merge additive HF PRs
        id: merge
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HUGGINGFACE_HUB_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO_ID: eatmorefruit/sharp-ply-share
          HF_REPO_TYPE: dataset
        run: |
          python - << 'PY'
          import io
          import json
          import os
          import re
          import sys
          import time
          from datetime import datetime, timezone
          from huggingface_hub import HfApi


          def ensure_coworker_discussion(api: HfApi, *, repo_id: str, repo_type: str) -> None:
              title = "coworker registration"
              body = "for automation"
              try:
                  for d in api.get_repo_discussions(
                      repo_id=repo_id,
                      repo_type=repo_type,
                      discussion_type="discussion",
                      discussion_status="open",
                  ):
                      try:
                          if str(getattr(d, "title", "") or "").strip() == title:
                              return
                      except Exception:
                          continue
              except Exception:
                  pass
              try:
                  api.create_discussion(repo_id=repo_id, repo_type=repo_type, title=title, description=body)
              except Exception as e:
                  print(f"WARN: create coworker discussion failed: {e}")


          def _env_str(k: str, default: str = "") -> str:
              v = os.getenv(k)
              if v is None:
                  return default
              return str(v)


          def _is_additive_only_diff(diff: str) -> bool:
              """Return True if this diff looks like only adding new files.

              Conservative rule:
              - Each file section must include `new file mode`.
              - Reject if any section contains deletions from an existing file (--- a/ not /dev/null).
              - Reject if any section contains `deleted file mode` or renames.
              """
              if not diff or not diff.strip():
                  return False

              # Split by file boundaries.
              parts = diff.split("diff --git ")
              # First part is header.
              file_parts = [p for p in parts[1:] if p.strip()]
              if not file_parts:
                  return False

              for p in file_parts:
                  # Hard rejects.
                  if "deleted file mode" in p:
                      return False
                  if "rename from" in p or "rename to" in p:
                      return False

                  # Must be a new file.
                  if "new file mode" not in p:
                      return False

                  # Expect old side to be /dev/null.
                  # Example:
                  # --- /dev/null
                  # +++ b/path
                  if re.search(r"^---\s+a/", p, flags=re.MULTILINE):
                      return False
                  if not re.search(r"^---\s+/dev/null\s*$", p, flags=re.MULTILINE):
                      return False
                  if not re.search(r"^\+\+\+\s+b/", p, flags=re.MULTILINE):
                      return False

              return True


          def main() -> int:
              token = _env_str("HF_TOKEN", "").strip()
              repo_id = _env_str("HF_REPO_ID", "").strip()
              repo_type = _env_str("HF_REPO_TYPE", "dataset").strip() or "dataset"

              if not token:
                  print("Missing HF_TOKEN", file=sys.stderr)
                  return 2
              if not repo_id:
                  print("Missing HF_REPO_ID", file=sys.stderr)
                  return 2

              api = HfApi(token=token)

              ensure_coworker_discussion(api, repo_id=repo_id, repo_type=repo_type)

              def cleanup_expired_coworker_prs() -> None:
                  try:
                      ttl_s = float(os.getenv("HF_COWORKER_PR_TTL_SECS", "1800") or "1800")
                  except Exception:
                      ttl_s = 1800.0
                  if ttl_s <= 0:
                      return

                  pat = re.compile(r"^coworker\s+(start|heartbeat|end)\b", flags=re.IGNORECASE)
                  now = time.time()
                  closed = 0
                  for d in api.get_repo_discussions(
                      repo_id=repo_id,
                      repo_type=repo_type,
                      discussion_type="pull_request",
                      discussion_status="open",
                  ):
                      try:
                          num = int(getattr(d, "num"))
                          title = str(getattr(d, "title", "") or "").strip()
                          if not pat.search(title):
                              continue

                          created_ts = None
                          try:
                              det = api.get_discussion_details(repo_id=repo_id, repo_type=repo_type, discussion_num=num)
                              created_at = getattr(det, "created_at", None)
                              if created_at:
                                  s = str(created_at)
                                  # Expect ISO format.
                                  dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
                                  if dt.tzinfo is None:
                                      dt = dt.replace(tzinfo=timezone.utc)
                                  created_ts = dt.timestamp()
                          except Exception:
                              created_ts = None

                          if created_ts is not None and (now - float(created_ts)) < float(ttl_s):
                              continue

                          api.change_discussion_status(
                              repo_id=repo_id,
                              repo_type=repo_type,
                              discussion_num=num,
                              new_status="closed",
                              comment="Archived: coworker coordination moved to discussion 'coworker registration'.",
                          )
                          closed += 1
                      except Exception as e:
                          print(f"WARN: close coworker PR failed: {e}")
                  if closed:
                      print(f"Closed expired coworker PRs: {closed}")

              cleanup_expired_coworker_prs()

              def update_coworkers_active() -> None:
                  ttl_s = 1800.0
                  try:
                      ttl_s = float(os.getenv("HF_COWORKER_TTL_SECS", "1800") or "1800")
                  except Exception:
                      ttl_s = 1800.0
                  if ttl_s <= 0:
                      ttl_s = 1800.0

                  base = str(os.getenv("HF_COWORKERS_DIR", "coworkers") or "coworkers").strip().strip("/")
                  events_prefix = f"{base}/events" if base else "events"
                  active_path = f"{base}/active.json" if base else "active.json"

                  latest_by_session = {}
                  try:
                      for ent in api.list_repo_tree(
                          repo_id=repo_id,
                          repo_type=repo_type,
                          path_in_repo=events_prefix,
                          recursive=True,
                      ):
                          p = None
                          for attr in ("path", "path_in_repo", "rfilename"):
                              if hasattr(ent, attr):
                                  try:
                                      p = getattr(ent, attr)
                                      break
                                  except Exception:
                                      p = None
                          if not p:
                              continue
                          p = str(p)
                          m = re.search(r"/(\d+)_([a-zA-Z0-9._-]+)\.json$", p)
                          if not m:
                              continue
                          tsms = int(m.group(1))
                          kind = str(m.group(2))
                          parts = [x for x in p.split("/") if x]
                          try:
                              i = parts.index("events")
                          except Exception:
                              try:
                                  i = parts.index(str(events_prefix).split("/")[-1])
                              except Exception:
                                  i = -1
                          if i < 0 or len(parts) < i + 4:
                              continue
                          owner = parts[i + 1]
                          sess = parts[i + 2]
                          key = (owner, sess)
                          prev = latest_by_session.get(key)
                          if prev is None or tsms > int(prev.get("tsms", 0)):
                              latest_by_session[key] = {"tsms": tsms, "kind": kind}
                  except Exception:
                      latest_by_session = {}

                  active_by_owner = {}
                  for (owner, sess), rec in (latest_by_session or {}).items():
                      try:
                          kind = str(rec.get("kind") or "")
                          if kind == "end":
                              continue
                          ts = float(int(rec.get("tsms") or 0)) / 1000.0
                          if ts <= 0:
                              continue
                          exp = float(ts) + float(ttl_s)
                          cur = active_by_owner.get(owner)
                          if cur is None or float(cur.get("last_ts") or 0.0) < float(ts):
                              active_by_owner[owner] = {"owner": str(owner), "last_ts": float(ts), "expires_ts": float(exp)}
                      except Exception:
                          continue

                  payload = {
                      "v": 1,
                      "ttl_s": float(ttl_s),
                      "active": [active_by_owner[k] for k in sorted(active_by_owner.keys())],
                  }
                  blob = (json.dumps(payload, ensure_ascii=False) + "\n").encode("utf-8")

                  old = None
                  try:
                      from huggingface_hub import hf_hub_download

                      old = hf_hub_download(repo_id=repo_id, repo_type=repo_type, filename=active_path)
                  except Exception:
                      old = None

                  if old:
                      try:
                          with open(old, "rb") as f:
                              old_b = f.read()
                          if old_b == blob:
                              return
                      except Exception:
                          pass

                  try:
                      from huggingface_hub import CommitOperationAdd

                      api.create_commit(
                          repo_id=repo_id,
                          repo_type=repo_type,
                          operations=[CommitOperationAdd(path_in_repo=active_path, path_or_fileobj=io.BytesIO(blob))],
                          commit_message="update coworkers/active.json",
                      )
                  except Exception as e:
                      print(f"WARN: update active.json failed: {e}")

              def run_once() -> tuple[int, int, int, int]:
                  merged = 0
                  skipped = 0
                  errors = 0
                  for d in api.get_repo_discussions(
                      repo_id=repo_id,
                      repo_type=repo_type,
                      discussion_type="pull_request",
                      discussion_status="open",
                  ):
                      try:
                          num = int(getattr(d, "num"))
                          title = str(getattr(d, "title", ""))
                          details = api.get_discussion_details(repo_id=repo_id, repo_type=repo_type, discussion_num=num)

                          # Skip conflicts.
                          conflicting = getattr(details, "conflicting_files", None)
                          if conflicting:
                              skipped += 1
                              print(f"SKIP PR#{num} (conflicts): {title} | conflicting_files={len(conflicting)}")
                              continue

                          diff = str(getattr(details, "diff", "") or "")
                          if not _is_additive_only_diff(diff):
                              skipped += 1
                              print(f"SKIP PR#{num} (non-additive): {title}")
                              continue

                          api.merge_pull_request(repo_id=repo_id, repo_type=repo_type, discussion_num=num)
                          merged += 1
                          print(f"MERGED PR#{num}: {title}")
                      except Exception as e:
                          errors += 1
                          print(f"ERROR processing PR: {e}")
                  print(f"Done | merged={merged} skipped={skipped} errors={errors}")
                  return (0 if errors == 0 else 1, merged, skipped, errors)

              rc, merged, skipped, errors = run_once()

              try:
                  update_coworkers_active()
              except Exception as e:
                  print(f"WARN: update_coworkers_active failed: {e}")

              did_work = "1" if int(merged) > 0 else "0"
              gh_out = os.getenv("GITHUB_OUTPUT")
              if gh_out:
                  with open(gh_out, "a", encoding="utf-8") as f:
                      f.write(f"did_work={did_work}\n")

              return int(rc)


          raise SystemExit(main())
          PY

      - name: Self-adjust schedule cron
        if: always()
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          DID_WORK: ${{ steps.merge.outputs.did_work }}
        run: |
          python - << 'PY'
          import os
          import re
          import subprocess

          pat = (os.getenv("GH_PAT") or "").strip()
          if not pat:
              print("GH_PAT not set; skipping cron self-adjust.")
              raise SystemExit(0)

          did_work = str(os.getenv("DID_WORK") or "0").strip()
          repo = str(os.getenv("GITHUB_REPOSITORY") or "").strip()
          ref_name = str(os.getenv("GITHUB_REF_NAME") or "main").strip() or "main"
          if not repo:
              print("Missing GITHUB_REPOSITORY; skipping.")
              raise SystemExit(0)

          path = ".github/workflows/hf-auto-merge-additive-prs.yml"
          with open(path, "r", encoding="utf-8") as f:
              txt = f.read()

          minutes = [5, 10, 20, 30, 60]
          max_level = len(minutes) - 1

          m = re.search(r"^\s*-\s*cron:\s*\"([^\"]+)\"\s*#\s*self-adapt\s+level=(\d+)\s*$", txt, flags=re.MULTILINE)
          if not m:
              print("Could not find self-adapt cron line; skipping.")
              raise SystemExit(0)

          old_level = int(m.group(2))
          old_level = max(0, min(max_level, old_level))

          if did_work == "1":
              new_level = 0
          else:
              new_level = min(max_level, old_level + 1)

          def level_to_cron(lv: int) -> str:
              mm = int(minutes[lv])
              if mm >= 60:
                  return "0 * * * *"
              return f"*/{mm} * * * *"

          new_cron = level_to_cron(new_level)
          old_line = m.group(0)
          indent = re.match(r"^(\s*)-\s*cron:", old_line).group(1)
          new_line = f"{indent}- cron: \"{new_cron}\"  # self-adapt level={new_level}"
          if old_line.strip() == new_line.strip():
              print("Cron unchanged; no commit.")
              raise SystemExit(0)

          txt2 = txt.replace(old_line, new_line, 1)
          with open(path, "w", encoding="utf-8") as f:
              f.write(txt2)

          subprocess.check_call(["git", "config", "user.name", "gha-cron-bot"])
          subprocess.check_call(["git", "config", "user.email", "gha-cron-bot@users.noreply.github.com"])
          subprocess.check_call(["git", "add", path])

          st = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True, check=False)
          if not (st.stdout or "").strip():
              print("No changes staged; skipping.")
              raise SystemExit(0)

          subprocess.check_call(["git", "commit", "-m", f"chore(gha): self-adjust auto-merge cron -> level {new_level}"])
          remote = f"https://x-access-token:{pat}@github.com/{repo}.git"
          subprocess.check_call(["git", "remote", "set-url", "origin", remote])
          subprocess.check_call(["git", "push", "origin", f"HEAD:{ref_name}"])
          print(f"Updated cron to: {new_cron} (level={new_level})")
          PY
